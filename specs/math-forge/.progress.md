# Math-Forge Harness Cleanup & Wiring

## Original Goal
Make math-forge the brain of the pipeline — fix 10 audit issues, wire KB queries into all pipeline skills, populate strategies table, remove stale configs. Math-forge should orchestrate everything, not be bolted on.

## Interview Format
- Version: 1.0

## Intent Classification
- Type: REFACTOR
- Confidence: high (4 keywords matched)
- Min questions: 3
- Max questions: 5
- Keywords matched: cleanup, fix, wire, consolidate

## Interview Responses

### Goal Interview (from start.md)
- Problem: Math-forge should be the brain — it should orchestrate the entire pipeline, not be an afterthought
- Constraints: Don't break the active pipeline — all 11 pipeline skills must keep working during and after changes
- Success criteria: All of the above — 10 audit issues fixed + KB consulted automatically + strategies table populated
- Additional context: Based on thorough audit of all 11 .claude/commands/ skills, 4 math-forge commands, 3 skills, 2 agents, 2 hooks, mk CLI, extract_findings.py, migrate_tracking.py, and schema.sql

## Audit Issues (10 identified)
1. strategies table: 0 rows, never populated — extract_findings.py doesn't write strategies
2. Stale Tuza-specific checks in audit.md — irrelevant for NT/algebra work
3. sweep.md still has Track D as viable — contradicts CLAUDE.md
4. Dual submission paths — INFORMAL bypasses safe_aristotle_submit.py safety checks
5. fetch.md Step 0 bash for-loop — fragile pattern
6. problem-researcher.md has placeholder path — /path/to/formal-conjectures
7. Duplicate knowledge.db — one at math-forge/knowledge.db (stray), one at math-forge/data/knowledge.db (correct)
8. extract_findings doesn't auto-run after fetch — manual step gap
9. mk find cross-DB query is fragile — silently returns nothing on path failure
10. Pipeline skills don't query KB before acting — sketch/submit/sweep should consult mk search/mk failed

## Learnings
- safe_aristotle_submit.py already supports --informal flag (line 355) -- no code changes needed for unified submission path
- math-forge/knowledge.db (0 bytes, git-tracked) is a stray; real DB is math-forge/data/knowledge.db (585KB, gitignored)
- KB has 502 findings (383 theorems, 56 failures, 43 false_lemmas, 20 techniques) but 0 strategies -- strategies table is a separate concept from mk strategies command
- Only 1 of 11 pipeline skills (sketch.md) queries knowledge.db; 7 skills query tracking.db but not knowledge.db
- extract_findings.py generates findings but never inserts strategies -- approach_name would need to be derived from filename/description
- The 43 false_lemma findings in knowledge.db overlap with tracking.db false_lemmas table, potentially making mk find's cross-DB query redundant
- All 32 BATS tests pass; bats 1.13.0 is installed. No tests exist for mk failed, extract_findings.py, or migrate_tracking.py
- screen-batch.md "Tier D -- RESEARCH" (open problems needing research) is NOT the same as Track D (known results) -- naming collision, not content issue
- context-loader.sh surfaces queue/proven/near-miss but not failed approaches or false lemmas in session briefing
- Only 2 proof techniques have significant counts: decide (169) and native_decide (100) -- all others are low frequency
- The mk strategies CLI command queries findings.proof_technique (works fine), while the strategies TABLE is for problem-level approach tracking (empty, different purpose)
